{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализатор текстовых пресс-релизов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: На основании исторических пресс-релизов кредитных рейтинговых агентств участникам хакатона необходимо построить интерпретируемую ML-модель, устанавливающую взаимосвязь между текстом пресс-релиза и присвоенным кредитным рейтингом по национальной рейтинговой шкале Российской Федерации для организации с учетом методологических особенностей оценки рейтинга. ML-модель должна не просто устанавливать соответствие текста пресс-релиза кредитному рейтингу, но также и выделять ключевые конструкции в тексте, соответствующие присвоенному кредитному рейтингу.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План\n",
    "\n",
    "Исходя из поставленной зажачи мы сформировали план\n",
    "1. Загрузить данные\n",
    "2. Оценить данные, если нужно, почистить, лематизировать\n",
    "3. Использовать для токенизации инструмент TfidfVectorizer\n",
    "4. Построить на основе полученных векторов разные модели предсказания кредитного рейтинга\n",
    "5. Использовать трансформер BERT\n",
    "6. Построить на основе полученных векторов разные модели предсказания кредитного рейтинга\n",
    "7. Оценить результаты и сделать выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from tqdm import notebook\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import torch\n",
    "import transformers as ppb\n",
    "import lightgbm as lgb\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import wordnet\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('CRA_train_1200.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Повышение кредитного рейтинга  Акционерного об...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>«Эксперт РА» подтвердил кредитный рейтинг комп...</td>\n",
       "      <td>BB</td>\n",
       "      <td>BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>НКР повысило кредитный рейтинг ООО \"ОТЭКО-Порт...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>«Эксперт РА» присвоил кредитный рейтинг ПАО «Ф...</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>29 марта 2023 г. Ведущий рейтинговый аналитик ...</td>\n",
       "      <td>BBB</td>\n",
       "      <td>BBB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text category rating\n",
       "0   1  Повышение кредитного рейтинга  Акционерного об...        A      A\n",
       "1   2  «Эксперт РА» подтвердил кредитный рейтинг комп...       BB     BB\n",
       "2   3  НКР повысило кредитный рейтинг ООО \"ОТЭКО-Порт...        A      A\n",
       "3   4  «Эксперт РА» присвоил кредитный рейтинг ПАО «Ф...      AAA    AAA\n",
       "4   5  29 марта 2023 г. Ведущий рейтинговый аналитик ...      BBB    BBB"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\n",
    "    'pr_txt': 'text',\n",
    "    'Категория': 'category',\n",
    "    'Уровень рейтинга': 'rating'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAM-token успешно получен:\n",
      "t1.9euelZqNl4rKyIyWj8uVjIyYi8uPme3rnpWajsuPjomPnpmWlcyLm4rKkZLl8_dQOQ1Y-e8eZUhw_N3z9xBoClj57x5lSHD8zef1656VmpfKjZCJm5ONmI2MiZXGyI6J7_zF656VmpfKjZCJm5ONmI2MiZXGyI6J.llqLEfGyAP56XQbvPIjbFYOxJAq3UW01P03pMj8UcNH0ZwwRPS0l_RLDX5HglQm6FKU9agHDyTTq0dfnCPNRDw\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Замените на свой OAuth-токен\n",
    "OAUTH_TOKEN = \"y0_AgAAAAAFvktuAATuwQAAAADsR6xABGN80xXHTc682VqotLAtG1s7dvY\"\n",
    "\n",
    "response = requests.post(\n",
    "    \"https://iam.api.cloud.yandex.net/iam/v1/tokens\",\n",
    "    data=json.dumps({\"yandexPassportOauthToken\": OAUTH_TOKEN}),\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    ")\n",
    "\n",
    "# Проверяем, что запрос прошел успешно\n",
    "if response.status_code == 200:\n",
    "    # Парсим ответ и извлекаем IAM-токен\n",
    "    iam_token = response.json()[\"iamToken\"]\n",
    "    print(\"IAM-token успешно получен:\")\n",
    "    print(iam_token)\n",
    "else:\n",
    "    print(f\"Не удалось получить IAM-token. Код ответа: {response.status_code}\")\n",
    "    print(\"Ответ сервера:\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to translate texts. Status code: 429\n",
      "Response text: {\n",
      " \"code\": 8,\n",
      " \"message\": \"grpc: received message larger than max (21546999 vs. 4194304)\",\n",
      " \"details\": [\n",
      "  {\n",
      "   \"@type\": \"type.googleapis.com/google.rpc.RequestInfo\",\n",
      "   \"requestId\": \"90f78806-6d6b-4414-8a3d-57ad75e84596\"\n",
      "  }\n",
      " ]\n",
      "}\n",
      "\n",
      "Failed to translate texts. Status code: 429\n",
      "Response text: {\n",
      " \"code\": 8,\n",
      " \"message\": \"grpc: received message larger than max (21546999 vs. 4194304)\",\n",
      " \"details\": [\n",
      "  {\n",
      "   \"@type\": \"type.googleapis.com/google.rpc.RequestInfo\",\n",
      "   \"requestId\": \"c4ff9671-61cb-4eb9-ac61-888ea7a95a17\"\n",
      "  }\n",
      " ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "IAM_TOKEN = 'y0_AgAAAAAFvktuAATuwQAAAADsR6xABGN80xXHTc682VqotLAtG1s7dvY'\n",
    "folder_id = '<идентификатор_каталога>'\n",
    "\n",
    "def translate_texts(texts, target_language):\n",
    "    body = {\n",
    "        \"targetLanguageCode\": target_language,\n",
    "        \"texts\": texts,\n",
    "        \"folderId\": folder_id,\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer {0}\".format(IAM_TOKEN)\n",
    "    }\n",
    "    \n",
    "    response = requests.post('https://translate.api.cloud.yandex.net/translate/v2/translate', json=body, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        res_json = response.json()\n",
    "        translated_texts = [text['text'] for text in res_json['translations']]\n",
    "        return translated_texts\n",
    "    else:\n",
    "        print(f\"Failed to translate texts. Status code: {response.status_code}\")\n",
    "        print(\"Response text:\", response.text)\n",
    "        return texts\n",
    "\n",
    "# Загрузите ваш датафрейм\n",
    "# data = pd.read_csv('path/to/your/data.csv')\n",
    "\n",
    "# Переведите тексты сначала на английский, затем обратно на русский\n",
    "data['translated_text_en'] = translate_texts(data['text'].tolist(), 'en')\n",
    "data['synthesized_text'] = translate_texts(data['translated_text_en'].tolist(), 'ru')\n",
    "\n",
    "# Удалим промежуточный столбец с английскими переводами\n",
    "data.drop(columns=['translated_text_en'], inplace=True)\n",
    "\n",
    "# Теперь у вас есть датафрейм с синтезированными текстами, которые были переведены на английский и обратно на русский\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to translate texts. Status code: 403\n",
      "Response text: {\n",
      " \"code\": 7,\n",
      " \"message\": \"Permission denied\",\n",
      " \"details\": [\n",
      "  {\n",
      "   \"@type\": \"type.googleapis.com/google.rpc.RequestInfo\",\n",
      "   \"requestId\": \"7dea240b-7e54-498f-a606-f6b7e9607f8c\"\n",
      "  }\n",
      " ]\n",
      "}\n",
      "\n",
      "Failed to translate texts. Status code: 403\n",
      "Response text: {\n",
      " \"code\": 7,\n",
      " \"message\": \"Permission denied\",\n",
      " \"details\": [\n",
      "  {\n",
      "   \"@type\": \"type.googleapis.com/google.rpc.RequestInfo\",\n",
      "   \"requestId\": \"35046249-8388-447f-9928-03055ef959b4\"\n",
      "  }\n",
      " ]\n",
      "}\n",
      "\n",
      "Original text: Повышение кредитного рейтинга  Акционерного общества «Уральская сталь»  (далее — «Уральская сталь», Компания) вызвано улучшением качественной оценки ликвидности в связи с рефинансированием краткосрочного банковского кредита посредством выпуска облигационного займа с погашением в 2025 году. Также пересмотр стратегических планов по реализации ряда инвестиционных проектов способствовал улучшению показателя «капитальные затраты к выручке». Улучшение ценовой конъюнктуры на мировом рынке чугуна обеспечило запуск доменной печи №3, находившейся ранее в резерве, что окажет дополнительное положительное влияние на денежный поток Компании в 2023 году.   Кредитный рейтинг Компании определяется средними рыночной позицией, бизнес-профилем и уровнем корпоративного управления, а также средней оценкой за размер бизнеса. Показатели рентабельности, ликвидности, долговой нагрузки, обслуживания долга и денежного потока получили высокие оценки.   «Уральская сталь» — один из крупнейших в России производителей товарного чугуна, мостостали и стали для производства труб большого диаметра (ТБД). В начале 2022 года Акционерное общество «Загорский трубный завод» ( рейтинг АКРА — <rating>, прогноз «Стабильный» ; далее — ЗТЗ) приобрело 100% уставного капитала Компании у АО «ХК «МЕТАЛЛОИНВЕСТ» ( рейтинг АКРА — <rating>, прогноз «Стабильный» ).  Ключевые факторы оценки     Средняя оценка рыночной позиции  обусловлена оценкой рыночных позиций «Уральской стали» по основным видам продукции (мостосталь, штрипс и чугун), взвешенных с учетом их доли в консолидированной выручке Компании.    Средняя оценка бизнес-профиля Компании  определяется: низкой оценкой степени вертикальной интеграции, которая отсутствует в Компании, поскольку она не обеспечена собственными углем и железорудным сырьем; средней оценкой за долю продукции с высокой добавленной стоимостью, которая учитывает сталь для ТБД и мостосталь как высокотехнологичные виды продукции; средней оценкой за характеристику и диверсификацию рынков сбыта, так как рынки сбыта основной продукции «Уральской стали» характеризуются умеренной цикличностью и насыщенностью, а продуктовый портфель Компании умеренно диверсифицирован.    Средняя оценка географической диверсификации  является следствием наличия экспорта чугуна, толстолистового проката и заготовки, доля которого формирует до 50% консолидированной выручки Компании. С одной стороны, это обуславливает высокую оценку субфактора «доступность и диверсификация рынков сбыта», а с другой — очень низкую оценку субфактора «концентрация на одном заводе».    Средний уровень корпоративного управления  обусловлен прозрачной структурой бизнеса и успешной реализацией Компанией стратегии роста и расширения продуктового портфеля. Топ-менеджмент Компании представлен экспертами с большим опытом работы в отрасли. «Уральская сталь» применяет отдельные элементы системы риск-менеджмента (например, хеджирование валютного риска в определенных случаях), однако единые документы по стратегии и управлению рисками, а также по дивидендной политике пока не утверждены. Совет директоров и ключевые комитеты пока не сформированы. Структура бизнеса проста. Компания готовит отчетность по МСФО.    Высокая оценка финансового риск-профиля Компании  обусловлена: высокой оценкой за рентабельность (рентабельность по FFO до процентов и налогов за 2022 год составила 12% и ожидается АКРА на уровне около 18% в 2023-м); высокой оценкой за обслуживание долга (отношение FFO до чистых процентных платежей к процентным платежам составило 24,7х по результатам 2022 года и прогнозируется АКРА на уровне около 11,7х в 2023-м); высокой оценкой за долговую нагрузку (отношение общего долга с учетом поручительства по долгу ЗТЗ к FFO до чистых процентных платежей ожидается АКРА на уровне 2,5х (0,8х без учета поручительств) по результатам 2023 года); средней оценкой размера бизнеса (абсолютное значение годового FFO до чистых процентных платежей и налогов — менее 30 млрд руб.).    Высокая оценка уровня ликвидности.  В декабре 2022 года Компания рефинансировала краткосрочный банковский долг за счет более долгосрочного облигационного займа с погашением в 2025 году. АКРА улучшило качественную оценку ликвидности Компании благодаря более комфортному графику погашения, а также наличию внутренних источников ликвидности в виде наличных средств и ожидаемому положительному свободному денежному потоку (FCF) по результатам 2023 года.    Высокая оценка денежного потока.  По результатам пересмотра стратегических планов по реализации ряда инвестиционных проектов капитальные расходы Компании были изменены в меньшую сторону, что оказало положительное влияние на показатель «капитальные затраты к выручке» и тем самым улучшило общую оценку фактора «денежный поток».  Ключевые допущения        капитальные затраты в соответствии с бизнес-планом;      отсутствие дивидендных выплат в прогнозном периоде.       Факторы возможного изменения прогноза или рейтинга     «Стабильный» прогноз  предполагает с высокой долей вероятности неизменность рейтинга на горизонте 12–18 месяцев.    К позитивному рейтинговому действию может привести:      снижение отношения общего долга с учетом поручительства по долгу ЗТЗ к FFO до чистых процентных платежей ниже 1,0х в сочетании с улучшением качественной оценки долговой нагрузки до высокой и ростом абсолютного значения FFO до чистых процентных платежей и налогов выше 30 млрд руб. в год.        К негативному рейтинговому действию могут привести:        повышение отношения общего долга с учетом поручительства по долгу ЗТЗ к FFO до чистых процентных платежей выше 2,0х;      снижение рентабельности по FFO до процентов и налогов ниже 15%;      снижение рентабельности по FCF ниже 5%, в том числе вследствие выплаты дивидендов.       Компоненты рейтинга    Оценка собственной кредитоспособности (ОСК):  a.    Корректировки: отсутствуют.  Рейтинги выпусков     Обоснование кредитного рейтинга.  Эмиссия является старшим необеспеченным долгом «Уральской стали». По причине отсутствия структурной и контрактной субординации выпуска АКРА оценивает эти облигации как равные по очередности исполнения другим существующим и будущим необеспеченным и несубординированным обязательствам Компании. В соответствии с методологией АКРА, для определения рейтинга эмиссии Агентство использовало детальный подход. Согласно расчетам АКРА, уровень возмещения по старшему необеспеченному долгу относится к I категории, в связи с чем кредитный рейтинг эмиссии приравнивается к кредитному рейтингу Компании — <rating>.    Бездокументарные процентные неконвертируемые биржевые облигации Акционерного общества «Уральская сталь» с централизованным учетом прав, размещаемые по открытой подписке, серия БО-001Р-01 (RU000A105Q63) , срок погашения — 25.12.2025, объем эмиссии — 10 млрд руб., — <rating>.  Регуляторное раскрытие    Кредитные рейтинги Акционерного общества «Уральская сталь» и выпуска облигаций Акционерного общества «Уральская сталь» (RU000A105Q63) были присвоены по национальной шкале для Российской Федерации на основе  Методологии присвоения кредитных рейтингов нефинансовым компаниям по национальной шкале для Российской Федерации  и  Основных понятий, используемых Аналитическим Кредитным Рейтинговым Агентством в рейтинговой деятельности . При присвоении кредитного рейтинга указанному выпуску облигаций также использовалась  Методология присвоения кредитных рейтингов финансовым инструментам по национальной шкале для Российской Федерации .   Впервые кредитный рейтинг Акционерного общества «Уральская сталь» был опубликован АКРА 14.12.2022, кредитный рейтинг выпуска облигаций (RU000A105Q63) — 29.12.2022. Очередной пересмотр кредитного рейтинга и прогноза по кредитному рейтингу Акционерного общества «Уральская сталь», а также кредитного рейтинга выпуска облигаций Акционерного общества «Уральская сталь» (RU000A105Q63) ожидается в течение одного года с даты опубликования настоящего пресс-релиза.   Кредитные рейтинги были присвоены на основании данных, предоставленных Акционерным обществом «Уральская сталь», информации из открытых источников, а также баз данных АКРА. Кредитные рейтинги были присвоены на основании отчетности Акционерного общества «Уральская сталь» по МСФО и РСБУ. Кредитные рейтинги являются запрошенными, Акционерное общество «Уральская сталь» принимало участие в процессе присвоения кредитных рейтингов.   При присвоении кредитных рейтингов использовалась информация, качество и достоверность которой, по мнению АКРА, являются надлежащими и достаточными для применения методологий.   АКРА не оказывало Акционерному обществу «Уральская сталь» дополнительных услуг. Конфликты интересов в рамках процесса присвоения кредитных рейтингов выявлены не были.\n",
      "Synthesized text: Повышение кредитного рейтинга  Акционерного общества «Уральская сталь»  (далее — «Уральская сталь», Компания) вызвано улучшением качественной оценки ликвидности в связи с рефинансированием краткосрочного банковского кредита посредством выпуска облигационного займа с погашением в 2025 году. Также пересмотр стратегических планов по реализации ряда инвестиционных проектов способствовал улучшению показателя «капитальные затраты к выручке». Улучшение ценовой конъюнктуры на мировом рынке чугуна обеспечило запуск доменной печи №3, находившейся ранее в резерве, что окажет дополнительное положительное влияние на денежный поток Компании в 2023 году.   Кредитный рейтинг Компании определяется средними рыночной позицией, бизнес-профилем и уровнем корпоративного управления, а также средней оценкой за размер бизнеса. Показатели рентабельности, ликвидности, долговой нагрузки, обслуживания долга и денежного потока получили высокие оценки.   «Уральская сталь» — один из крупнейших в России производителей товарного чугуна, мостостали и стали для производства труб большого диаметра (ТБД). В начале 2022 года Акционерное общество «Загорский трубный завод» ( рейтинг АКРА — <rating>, прогноз «Стабильный» ; далее — ЗТЗ) приобрело 100% уставного капитала Компании у АО «ХК «МЕТАЛЛОИНВЕСТ» ( рейтинг АКРА — <rating>, прогноз «Стабильный» ).  Ключевые факторы оценки     Средняя оценка рыночной позиции  обусловлена оценкой рыночных позиций «Уральской стали» по основным видам продукции (мостосталь, штрипс и чугун), взвешенных с учетом их доли в консолидированной выручке Компании.    Средняя оценка бизнес-профиля Компании  определяется: низкой оценкой степени вертикальной интеграции, которая отсутствует в Компании, поскольку она не обеспечена собственными углем и железорудным сырьем; средней оценкой за долю продукции с высокой добавленной стоимостью, которая учитывает сталь для ТБД и мостосталь как высокотехнологичные виды продукции; средней оценкой за характеристику и диверсификацию рынков сбыта, так как рынки сбыта основной продукции «Уральской стали» характеризуются умеренной цикличностью и насыщенностью, а продуктовый портфель Компании умеренно диверсифицирован.    Средняя оценка географической диверсификации  является следствием наличия экспорта чугуна, толстолистового проката и заготовки, доля которого формирует до 50% консолидированной выручки Компании. С одной стороны, это обуславливает высокую оценку субфактора «доступность и диверсификация рынков сбыта», а с другой — очень низкую оценку субфактора «концентрация на одном заводе».    Средний уровень корпоративного управления  обусловлен прозрачной структурой бизнеса и успешной реализацией Компанией стратегии роста и расширения продуктового портфеля. Топ-менеджмент Компании представлен экспертами с большим опытом работы в отрасли. «Уральская сталь» применяет отдельные элементы системы риск-менеджмента (например, хеджирование валютного риска в определенных случаях), однако единые документы по стратегии и управлению рисками, а также по дивидендной политике пока не утверждены. Совет директоров и ключевые комитеты пока не сформированы. Структура бизнеса проста. Компания готовит отчетность по МСФО.    Высокая оценка финансового риск-профиля Компании  обусловлена: высокой оценкой за рентабельность (рентабельность по FFO до процентов и налогов за 2022 год составила 12% и ожидается АКРА на уровне около 18% в 2023-м); высокой оценкой за обслуживание долга (отношение FFO до чистых процентных платежей к процентным платежам составило 24,7х по результатам 2022 года и прогнозируется АКРА на уровне около 11,7х в 2023-м); высокой оценкой за долговую нагрузку (отношение общего долга с учетом поручительства по долгу ЗТЗ к FFO до чистых процентных платежей ожидается АКРА на уровне 2,5х (0,8х без учета поручительств) по результатам 2023 года); средней оценкой размера бизнеса (абсолютное значение годового FFO до чистых процентных платежей и налогов — менее 30 млрд руб.).    Высокая оценка уровня ликвидности.  В декабре 2022 года Компания рефинансировала краткосрочный банковский долг за счет более долгосрочного облигационного займа с погашением в 2025 году. АКРА улучшило качественную оценку ликвидности Компании благодаря более комфортному графику погашения, а также наличию внутренних источников ликвидности в виде наличных средств и ожидаемому положительному свободному денежному потоку (FCF) по результатам 2023 года.    Высокая оценка денежного потока.  По результатам пересмотра стратегических планов по реализации ряда инвестиционных проектов капитальные расходы Компании были изменены в меньшую сторону, что оказало положительное влияние на показатель «капитальные затраты к выручке» и тем самым улучшило общую оценку фактора «денежный поток».  Ключевые допущения        капитальные затраты в соответствии с бизнес-планом;      отсутствие дивидендных выплат в прогнозном периоде.       Факторы возможного изменения прогноза или рейтинга     «Стабильный» прогноз  предполагает с высокой долей вероятности неизменность рейтинга на горизонте 12–18 месяцев.    К позитивному рейтинговому действию может привести:      снижение отношения общего долга с учетом поручительства по долгу ЗТЗ к FFO до чистых процентных платежей ниже 1,0х в сочетании с улучшением качественной оценки долговой нагрузки до высокой и ростом абсолютного значения FFO до чистых процентных платежей и налогов выше 30 млрд руб. в год.        К негативному рейтинговому действию могут привести:        повышение отношения общего долга с учетом поручительства по долгу ЗТЗ к FFO до чистых процентных платежей выше 2,0х;      снижение рентабельности по FFO до процентов и налогов ниже 15%;      снижение рентабельности по FCF ниже 5%, в том числе вследствие выплаты дивидендов.       Компоненты рейтинга    Оценка собственной кредитоспособности (ОСК):  a.    Корректировки: отсутствуют.  Рейтинги выпусков     Обоснование кредитного рейтинга.  Эмиссия является старшим необеспеченным долгом «Уральской стали». По причине отсутствия структурной и контрактной субординации выпуска АКРА оценивает эти облигации как равные по очередности исполнения другим существующим и будущим необеспеченным и несубординированным обязательствам Компании. В соответствии с методологией АКРА, для определения рейтинга эмиссии Агентство использовало детальный подход. Согласно расчетам АКРА, уровень возмещения по старшему необеспеченному долгу относится к I категории, в связи с чем кредитный рейтинг эмиссии приравнивается к кредитному рейтингу Компании — <rating>.    Бездокументарные процентные неконвертируемые биржевые облигации Акционерного общества «Уральская сталь» с централизованным учетом прав, размещаемые по открытой подписке, серия БО-001Р-01 (RU000A105Q63) , срок погашения — 25.12.2025, объем эмиссии — 10 млрд руб., — <rating>.  Регуляторное раскрытие    Кредитные рейтинги Акционерного общества «Уральская сталь» и выпуска облигаций Акционерного общества «Уральская сталь» (RU000A105Q63) были присвоены по национальной шкале для Российской Федерации на основе  Методологии присвоения кредитных рейтингов нефинансовым компаниям по национальной шкале для Российской Федерации  и  Основных понятий, используемых Аналитическим Кредитным Рейтинговым Агентством в рейтинговой деятельности . При присвоении кредитного рейтинга указанному выпуску облигаций также использовалась  Методология присвоения кредитных рейтингов финансовым инструментам по национальной шкале для Российской Федерации .   Впервые кредитный рейтинг Акционерного общества «Уральская сталь» был опубликован АКРА 14.12.2022, кредитный рейтинг выпуска облигаций (RU000A105Q63) — 29.12.2022. Очередной пересмотр кредитного рейтинга и прогноза по кредитному рейтингу Акционерного общества «Уральская сталь», а также кредитного рейтинга выпуска облигаций Акционерного общества «Уральская сталь» (RU000A105Q63) ожидается в течение одного года с даты опубликования настоящего пресс-релиза.   Кредитные рейтинги были присвоены на основании данных, предоставленных Акционерным обществом «Уральская сталь», информации из открытых источников, а также баз данных АКРА. Кредитные рейтинги были присвоены на основании отчетности Акционерного общества «Уральская сталь» по МСФО и РСБУ. Кредитные рейтинги являются запрошенными, Акционерное общество «Уральская сталь» принимало участие в процессе присвоения кредитных рейтингов.   При присвоении кредитных рейтингов использовалась информация, качество и достоверность которой, по мнению АКРА, являются надлежащими и достаточными для применения методологий.   АКРА не оказывало Акционерному обществу «Уральская сталь» дополнительных услуг. Конфликты интересов в рамках процесса присвоения кредитных рейтингов выявлены не были.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Замените на свои реальные данные\n",
    "IAM_TOKEN = iam_token\n",
    "folder_id = '<идентификатор_каталога>'\n",
    "\n",
    "def translate_texts(texts, target_language):\n",
    "    body = {\n",
    "        \"targetLanguageCode\": target_language,\n",
    "        \"texts\": texts,\n",
    "        \"folderId\": folder_id,\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer {0}\".format(IAM_TOKEN)\n",
    "    }\n",
    "    \n",
    "    response = requests.post('https://translate.api.cloud.yandex.net/translate/v2/translate', json=body, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        res_json = response.json()\n",
    "        translated_texts = [text['text'] for text in res_json['translations']]\n",
    "        return translated_texts\n",
    "    else:\n",
    "        print(f\"Failed to translate texts. Status code: {response.status_code}\")\n",
    "        print(\"Response text:\", response.text)\n",
    "        return texts\n",
    "\n",
    "# Загрузите ваш датафрейм\n",
    "# data = pd.read_csv('path/to/your/data.csv')\n",
    "\n",
    "# Получите первую строку текста для перевода\n",
    "first_text = [data.loc[0, 'text']]\n",
    "\n",
    "# Переведите текст сначала на английский, затем обратно на русский\n",
    "translated_text_to_en = translate_texts(first_text, 'en')\n",
    "synthesized_text = translate_texts(translated_text_to_en, 'ru')\n",
    "\n",
    "# Печать оригинального и синтезированного текстов\n",
    "print(\"Original text:\", first_text[0])\n",
    "print(\"Synthesized text:\", synthesized_text[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting nlpaug\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nlpaug) (2.27.1)\n",
      "Collecting gdown>=4.0.0\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nlpaug) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\karimovdo\\appdata\\roaming\\python\\python39\\site-packages (from nlpaug) (1.23.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (3.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.64.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.11.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karimovdo\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karimovdo\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.22.0->nlpaug) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (1.26.9)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.3.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->gdown>=4.0.0->nlpaug) (0.4.4)\n",
      "Installing collected packages: gdown, nlpaug\n",
      "Successfully installed gdown-4.7.1 nlpaug-1.1.11\n"
     ]
    }
   ],
   "source": [
    "pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\KarimovDO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\KarimovDO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\KarimovDO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'path\\to\\save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KarimovDO\\Documents\\GitHub\\medis_cor\\hak1\\h.ipynb Ячейка 12\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KarimovDO/Documents/GitHub/medis_cor/hak1/h.ipynb#X62sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m final_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([data[[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m]], synthesized_data])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KarimovDO/Documents/GitHub/medis_cor/hak1/h.ipynb#X62sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Сохраните финальный датафрейм\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KarimovDO/Documents/GitHub/medis_cor/hak1/h.ipynb#X62sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m final_data\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39mpath/to/save/final_data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3540\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3542\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3543\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3544\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3548\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3549\u001b[0m )\n\u001b[1;32m-> 3551\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3552\u001b[0m     path_or_buf,\n\u001b[0;32m   3553\u001b[0m     line_terminator\u001b[39m=\u001b[39;49mline_terminator,\n\u001b[0;32m   3554\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3555\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3556\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3557\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3558\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3559\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3560\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3561\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3562\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3563\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3564\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3565\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3566\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3567\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3568\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1162\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1163\u001b[0m     line_terminator\u001b[39m=\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1179\u001b[0m )\n\u001b[1;32m-> 1180\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1182\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1183\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:697\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 697\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    699\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    701\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:571\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    569\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'path\\to\\save'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Загрузите ваш датафрейм\n",
    "\n",
    "\n",
    "# Создайте аугментер\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "def augment_text(text):\n",
    "    return aug.augment(text)\n",
    "\n",
    "# Примените аугментацию к каждой строке в столбце 'text'\n",
    "data['synthesized_text'] = data['text'].apply(augment_text)\n",
    "\n",
    "# Сохраните исходные данные и синтезированные данные в новом датафрейме\n",
    "synthesized_data = data[['synthesized_text', 'category', 'rating']]\n",
    "synthesized_data.columns = ['text', 'category', 'rating']\n",
    "\n",
    "# Объедините исходные и синтезированные данные\n",
    "final_data = pd.concat([data[['text', 'category', 'rating']], synthesized_data])\n",
    "\n",
    "# Сохраните финальный датафрейм\n",
    "final_data.to_csv('path/to/save/final_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    'C': 0, \n",
    "    'B': 1, \n",
    "    'BB': 2, \n",
    "    'BBB': 3, \n",
    "    'A': 4, \n",
    "    'AA': 5, \n",
    "    'AAA': 6\n",
    "}\n",
    "\n",
    "data['category_num'] = data['category'].replace(category_mapping)\n",
    "\n",
    "rating_mapping = {\n",
    "    'C': 0, \n",
    "    'B-': 1, \n",
    "    'B': 2, \n",
    "    'B+': 3, \n",
    "    'BB-': 4, \n",
    "    'BB': 5, \n",
    "    'BB+': 6, \n",
    "    'BBB-': 7, \n",
    "    'BBB': 8, \n",
    "    'BBB+': 9, \n",
    "    'A-': 10, \n",
    "    'A': 11, \n",
    "    'A+': 12, \n",
    "    'AA-': 13, \n",
    "    'AA': 14, \n",
    "    'AA+': 15, \n",
    "    'AAA': 16\n",
    "}\n",
    "\n",
    "data['rating_num'] = data['rating'].replace(rating_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id                                               text category rating  \\\n",
      "0   1  Повышение кредитного рейтинга  Акционерного об...        A      A   \n",
      "1   2  «Эксперт РА» подтвердил кредитный рейтинг комп...       BB     BB   \n",
      "2   3  НКР повысило кредитный рейтинг ООО \"ОТЭКО-Порт...        A      A   \n",
      "3   4  «Эксперт РА» присвоил кредитный рейтинг ПАО «Ф...      AAA    AAA   \n",
      "4   5  29 марта 2023 г. Ведущий рейтинговый аналитик ...      BBB    BBB   \n",
      "\n",
      "   category_num  rating_num  АКРА_count  Эксперт_РА_count  НКР_count  \\\n",
      "0             4          11          13                 0          0   \n",
      "1             2           5           0                15          0   \n",
      "2             4          11           0                 0         23   \n",
      "3             6          16           0                16          0   \n",
      "4             3           8           0                 0          0   \n",
      "\n",
      "   НРА_count      Agency  \n",
      "0          0        АКРА  \n",
      "1          0  Эксперт_РА  \n",
      "2          0         НКР  \n",
      "3          0  Эксперт_РА  \n",
      "4         12         НРА  \n"
     ]
    }
   ],
   "source": [
    "data['АКРА_count'] = data['text'].str.count('АКРА')\n",
    "data['Эксперт_РА_count'] = data['text'].str.count('Эксперт РА')\n",
    "data['НКР_count'] = data['text'].str.count('НКР')\n",
    "data['НРА_count'] = data['text'].str.count('НРА')\n",
    "\n",
    "# Функция для определения агентства с наибольшим числом упоминаний\n",
    "def most_frequent_agency(row):\n",
    "    max_count = row.max()\n",
    "    \n",
    "    if max_count == 0 or (row == max_count).sum() > 1:\n",
    "        return 'АКРА'\n",
    "    else:\n",
    "        return row.idxmax().replace('_count', '')\n",
    "\n",
    "# Создание нового столбца с помощью функции\n",
    "count_columns = ['АКРА_count', 'Эксперт_РА_count', 'НКР_count', 'НРА_count']\n",
    "data['Agency'] = data[count_columns].apply(most_frequent_agency, axis=1)\n",
    "\n",
    "# Отображаем первые несколько строк датафрейма для проверки\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['АКРА', 'Эксперт_РА', 'НКР', 'НРА'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Agency'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Zа-яА-Я ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pymystem3 import Mystem\n",
    "# from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# m = Mystem()\n",
    "\n",
    "# # Загрузка русских стоп-слов\n",
    "# russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "\n",
    "\n",
    "# def lemmatize_text(corpus):\n",
    "#     corpus_new = []\n",
    "#     for sentence in tqdm(corpus):\n",
    "#         lemmatized_sentence = m.lemmatize(sentence)\n",
    "#         cleaned_sentence = ' '.join([word for word in lemmatized_sentence if word.strip() and word not in russian_stopwords])\n",
    "#         corpus_new.append(cleaned_sentence)\n",
    "#     return corpus_new\n",
    "\n",
    "\n",
    "\n",
    "# data['text_lemmatized'] = lemmatize_text(data['text'])\n",
    "\n",
    "# print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters for category are: {'model': SVC(C=10, kernel='linear', random_state=42), 'model__C': 10, 'model__kernel': 'linear'}\n",
      "Best cross-validation score for category is: 0.7785740652466765\n",
      "Test F1 score for category is: 0.8241440265049673\n",
      "Final TEST F1 score for 'category': 0.8241440265049673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Загрузите данные\n",
    "\n",
    "nltk_stopwords = list(nltk_stopwords.words('russian'))\n",
    "extra_stopwords = [\n",
    "    # (Ваш список стоп-слов)\n",
    "]\n",
    "nltk_stopwords.extend(extra_stopwords)\n",
    "count_tf_idf = TfidfVectorizer(stop_words=nltk_stopwords)\n",
    "\n",
    "def train_model(target_col, agency):\n",
    "    # Фильтрация данных по конкретному агентству\n",
    "    agency_data = data[data['Agency'] == agency]\n",
    "    \n",
    "    # Извлекаем признаки и целевую переменную\n",
    "    X = agency_data['text']\n",
    "    y = agency_data[target_col].values\n",
    "\n",
    "    # Разделите данные на тренировочные и тестовые наборы\n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "    except ValueError:\n",
    "        # В случае ошибки отключаем стратификацию\n",
    "        print(f\"Stratification failed for {target_col}. Proceeding without stratification.\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    # Примените TF-IDF векторизатор к вашим данным\n",
    "    tfidf_train = count_tf_idf.fit_transform(X_train)\n",
    "    tfidf_test = count_tf_idf.transform(X_test)\n",
    "\n",
    "    # Определите конвейер и сетку параметров для поиска по сетке\n",
    "    pipe = Pipeline([\n",
    "        ('model', LogisticRegression(random_state=1, solver='liblinear', max_iter=200))\n",
    "    ])\n",
    "\n",
    "    param_grid = [\n",
    "        {\n",
    "            'model': [LogisticRegression(random_state=42, solver='liblinear')],\n",
    "            'model__C': list(range(1, 15, 3)),\n",
    "            'model__penalty': ['l1', 'l2']\n",
    "        },\n",
    "        {\n",
    "            'model': [SVC(random_state=42)],\n",
    "            'model__C': [0.1, 1, 10],\n",
    "            'model__kernel': ['linear', 'rbf']\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Проведите поиск по сетке, чтобы найти наилучшие параметры\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring=make_scorer(f1_score, average='weighted'), cv=5, verbose=True, n_jobs=-1)\n",
    "    best_grid = grid.fit(tfidf_train, y_train)\n",
    "    \n",
    "    # Сохраните модель\n",
    "    joblib.dump(best_grid, f\"{agency}_{target_col}_model.joblib\")\n",
    "\n",
    "    # Выведите наилучшие параметры и оценку\n",
    "    print(f\"Best parameters for {target_col} are:\", grid.best_params_)\n",
    "    print(f\"Best cross-validation score for {target_col} is:\", grid.best_score_)\n",
    "\n",
    "    # Проверка на тестовой выборке\n",
    "    test_predictions = best_grid.predict(tfidf_test)\n",
    "    test_score = f1_score(y_test, test_predictions, average='weighted')\n",
    "    print(f\"Test F1 score for {target_col} is:\", test_score)\n",
    "    \n",
    "    return grid.best_score_, test_score\n",
    "\n",
    "# Создание словаря для хранения обученных моделей\n",
    "models = {}\n",
    "\n",
    "# Обучите модели для каждого агентства\n",
    " \n",
    "for agency in data['Agency'].unique():\n",
    "    print(f\"Training model for agency: {agency}\")\n",
    "    models[agency] = train_model('category', agency)\n",
    "\n",
    "test_scores = [scores[1] for scores in models.values()]\n",
    "\n",
    "# Вычисляем среднее значение\n",
    "average_test_score = sum(test_scores) / len(test_scores)\n",
    "\n",
    "print(f\"The average test F1 score is: {average_test_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters for category are: {'model': SVC(C=10, kernel='linear', random_state=42), 'model__C': 10, 'model__kernel': 'linear'}\n",
      "Best cross-validation score for category is: 0.7785740652466765\n",
      "Test F1 score for category is: 0.8241440265049673\n",
      "Final CV F1 score for 'category': 0.7785740652466765\n",
      "Final TEST F1 score for 'category': 0.8241440265049673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "nltk_stopwords = list(nltk_stopwords.words('russian'))\n",
    "extra_stopwords = [\n",
    "        'далее', 'также', 'что', 'в', 'с', 'и', 'на', 'по', 'а', 'за', '—', 'как', \n",
    "    'у', 'до', 'средней', 'очень', 'один', 'это', 'средняя', '«', '»', '(', ')', \n",
    "    '№', '—', 'году', 'одной', 'посредством', 'ранее', 'большого', 'которая', \n",
    "    'который', 'этом', 'является', 'один', 'другой', 'доли', 'доля', 'их', \n",
    "    'которого', 'его', 'средний', 'средние', 'уровень', 'производителей', \n",
    "    'высокие', 'низкой', 'средней', 'продукции', 'компании', 'компания', \n",
    "    'продукция', 'оценка', 'оценки', 'оценку', 'показатели', 'показатель', \n",
    "    'факторы', 'фактор', 'уровня', 'профиля', 'бизнес', 'бизнеса', 'уровень', \n",
    "    'уровня', 'рейтинг', 'рейтинга', 'рейтингу', 'производства', 'производство'\n",
    "]\n",
    "nltk_stopwords.extend(extra_stopwords)\n",
    "count_tf_idf = TfidfVectorizer(stop_words=nltk_stopwords)\n",
    "\n",
    "def train_model(target_col):\n",
    "    # Извлекаем признаки и целевую переменную\n",
    "    X = data['text']\n",
    "    y = data[target_col].values\n",
    "\n",
    "    # Разделите данные на тренировочные и тестовые наборы\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "    # Примените TF-IDF векторизатор к вашим данным\n",
    "    tfidf_train = count_tf_idf.fit_transform(X_train)\n",
    "    tfidf_test = count_tf_idf.transform(X_test)\n",
    "\n",
    "    # Определите конвейер и сетку параметров для поиска по сетке\n",
    "    pipe = Pipeline([\n",
    "        ('model', LogisticRegression(random_state=1, solver='liblinear', max_iter=200))\n",
    "    ])\n",
    "\n",
    "    param_grid = [\n",
    "        {\n",
    "            'model': [LogisticRegression(random_state=42, solver='liblinear')],\n",
    "            'model__C': list(range(1, 15, 3)),\n",
    "            'model__penalty': ['l1', 'l2']\n",
    "        },\n",
    "        {\n",
    "            'model': [SVC(random_state=42)],\n",
    "            'model__C': [0.1, 1, 10],\n",
    "            'model__kernel': ['linear', 'rbf']\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Проведите поиск по сетке, чтобы найти наилучшие параметры\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring=make_scorer(f1_score, average='weighted'), cv=5, verbose=True, n_jobs=-1)\n",
    "    best_grid = grid.fit(tfidf_train, y_train)\n",
    "    \n",
    "    # Выведите наилучшие параметры и оценку\n",
    "    print(f\"Best parameters for {target_col} are:\", grid.best_params_)\n",
    "    print(f\"Best cross-validation score for {target_col} is:\", grid.best_score_)\n",
    "\n",
    "    # Проверка на тестовой выборке\n",
    "    test_predictions = best_grid.predict(tfidf_test)\n",
    "    test_score = f1_score(y_test, test_predictions, average='weighted')\n",
    "    print(f\"Test F1 score for {target_col} is:\", test_score)\n",
    "    joblib.dump(best_grid.best_estimator_, f'best_model_{target_col}.joblib')\n",
    "    return grid.best_score_, test_score\n",
    "\n",
    "# Получите лучшие оценки для 'category'\n",
    "category_cv_f1, category_test_f1 = train_model('category')\n",
    "\n",
    "print(f\"Final CV F1 score for 'category': {category_cv_f1}\")\n",
    "print(f\"Final TEST F1 score for 'category': {category_test_f1}\")\n",
    "\n",
    "best_model = joblib.load('best_model_category.joblib')\n",
    "\n",
    "# Примените TF-IDF векторизатор к вашим данным\n",
    "tfidf_data = count_tf_idf.transform(data['text'])\n",
    "\n",
    "# Предсказание категорий\n",
    "data['category_pred'] = best_model.predict(tfidf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KarimovDO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score: 0.7427151024753764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_rating.joblib']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Загружаем стоп-слова\n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords = list(stopwords.words('russian'))\n",
    "extra_stopwords = [\n",
    "        'далее', 'также', 'что', 'в', 'с', 'и', 'на', 'по', 'а', 'за', '—', 'как', \n",
    "    'у', 'до', 'средней', 'очень', 'один', 'это', 'средняя', '«', '»', '(', ')', \n",
    "    '№', '—', 'году', 'одной', 'посредством', 'ранее', 'большого', 'которая', \n",
    "    'который', 'этом', 'является', 'один', 'другой', 'доли', 'доля', 'их', \n",
    "    'которого', 'его', 'средний', 'средние', 'уровень', 'производителей', \n",
    "    'высокие', 'низкой', 'средней', 'продукции', 'компании', 'компания', \n",
    "    'продукция', 'оценка', 'оценки', 'оценку', 'показатели', 'показатель', \n",
    "    'факторы', 'фактор', 'уровня', 'профиля', 'бизнес', 'бизнеса', 'уровень', \n",
    "    'уровня', 'рейтинг', 'рейтинга', 'рейтингу', 'производства', 'производство'\n",
    "]\n",
    "nltk_stopwords.extend(extra_stopwords)\n",
    "count_tf_idf = TfidfVectorizer(stop_words=nltk_stopwords)\n",
    "\n",
    "X_text_tfidf = count_tf_idf.fit_transform(data['text'])\n",
    "\n",
    "# Применяем OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "X_category_ohe = ohe.fit_transform(data[['category_pred']])\n",
    "\n",
    "# Объединяем преобработанные признаки\n",
    "from scipy.sparse import hstack\n",
    "X = hstack([X_text_tfidf, X_category_ohe])\n",
    "\n",
    "# Разделяем данные на тренировочные и тестовые наборы\n",
    "y = data['rating'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "model = SVC(C=10, kernel='linear', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Оцениваем модель на тестовом наборе\n",
    "y_pred = model.predict(X_test)\n",
    "test_f1_score = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'Test F1 score: {test_f1_score}')\n",
    "\n",
    "joblib.dump(model, 'model_rating.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7712152258857332"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_score = (test_f1_score * 0.65) + (category_test_f1 * 0.35) \n",
    "final_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters for rating are: {'model': SVC(C=10, kernel='linear', random_state=42), 'model__C': 10, 'model__kernel': 'linear'}\n",
      "Best cross-validation score for rating is: 0.6106691542561378\n",
      "Test F1 score for rating is: 0.6764194855512256\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters for category are: {'model': SVC(C=10, kernel='linear', random_state=42), 'model__C': 10, 'model__kernel': 'linear'}\n",
      "Best cross-validation score for category is: 0.7785740652466765\n",
      "Test F1 score for category is: 0.8241440265049673\n",
      "Final CV F1 score for 'rating': 0.6106691542561378\n",
      "Final CV F1 score for 'category': 0.7785740652466765\n",
      "Overall final CV score: 0.6694358731028263\n",
      "Final TEST F1 score for 'rating': 0.6764194855512256\n",
      "Final TEST F1 score for 'category': 0.8241440265049673\n",
      "Overall final TEST score: 0.7281230748850351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "nltk_stopwords = list(nltk_stopwords.words('russian'))\n",
    "extra_stopwords = [\n",
    "    'далее', 'также', 'что', 'в', 'с', 'и', 'на', 'по', 'а', 'за', '—', 'как', \n",
    "    'у', 'до', 'средней', 'очень', 'один', 'это', 'средняя', '«', '»', '(', ')', \n",
    "    '№', '—', 'году', 'одной', 'посредством', 'ранее', 'большого', 'которая', \n",
    "    'который', 'этом', 'является', 'один', 'другой', 'доли', 'доля', 'их', \n",
    "    'которого', 'его', 'средний', 'средние', 'уровень', 'производителей', \n",
    "    'высокие', 'низкой', 'средней', 'продукции', 'компании', 'компания', \n",
    "    'продукция', 'оценка', 'оценки', 'оценку', 'показатели', 'показатель', \n",
    "    'факторы', 'фактор', 'уровня', 'профиля', 'бизнес', 'бизнеса', 'уровень', \n",
    "    'уровня', 'рейтинг', 'рейтинга', 'рейтингу', 'производства', 'производство'\n",
    "]\n",
    "nltk_stopwords.extend(extra_stopwords)\n",
    "count_tf_idf = TfidfVectorizer(stop_words=nltk_stopwords)\n",
    "\n",
    "def train_model(target_col):\n",
    "    # Извлекаем признаки и целевую переменную\n",
    "    X = data['text']\n",
    "    y = data[target_col].values\n",
    "\n",
    "    # Разделите данные на тренировочные и тестовые наборы\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "    # Примените TF-IDF векторизатор к вашим данным\n",
    "    tfidf_train = count_tf_idf.fit_transform(X_train)\n",
    "    tfidf_test = count_tf_idf.transform(X_test)\n",
    "\n",
    "    # Определите конвейер и сетку параметров для поиска по сетке\n",
    "    pipe = Pipeline([\n",
    "        ('model', LogisticRegression(random_state=1, solver='liblinear', max_iter=200))\n",
    "    ])\n",
    "\n",
    "    param_grid = [\n",
    "    {\n",
    "        'model': [LogisticRegression(random_state=42, solver='liblinear')],\n",
    "        'model__C': list(range(1, 15, 3)),\n",
    "        'model__penalty': ['l1', 'l2']\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'model': [SVC(random_state=42)],\n",
    "        'model__C': [0.1, 1, 10],\n",
    "        'model__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "\n",
    "    ]\n",
    "\n",
    "        # Проведите поиск по сетке, чтобы найти наилучшие параметры\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring=make_scorer(f1_score, average='weighted'), cv=5, verbose=True, n_jobs=-1)\n",
    "    best_grid = grid.fit(tfidf_train, y_train)\n",
    "    \n",
    "    # Выведите наилучшие параметры и оценку\n",
    "    print(f\"Best parameters for {target_col} are:\", grid.best_params_)\n",
    "    print(f\"Best cross-validation score for {target_col} is:\", grid.best_score_)\n",
    "\n",
    "    # Проверка на тестовой выборке\n",
    "    tfidf_test = count_tf_idf.transform(X_test)\n",
    "    test_predictions = best_grid.predict(tfidf_test)\n",
    "    test_score = f1_score(y_test, test_predictions, average='weighted')\n",
    "    print(f\"Test F1 score for {target_col} is:\", test_score)\n",
    "    \n",
    "    return grid.best_score_, test_score\n",
    "\n",
    "# Получите лучшие оценки для каждой целевой переменной\n",
    "rating_cv_f1, rating_test_f1 = train_model('rating')\n",
    "category_cv_f1, category_test_f1 = train_model('category')\n",
    "\n",
    "# Рассчитайте взвешенный итоговый результат\n",
    "final_cv_score = (rating_cv_f1 * 0.65) + (category_cv_f1 * 0.35)\n",
    "final_test_score = (rating_test_f1 * 0.65) + (category_test_f1 * 0.35)\n",
    "\n",
    "print(f\"Final CV F1 score for 'rating': {rating_cv_f1}\")\n",
    "print(f\"Final CV F1 score for 'category': {category_cv_f1}\")\n",
    "print(f\"Overall final CV score: {final_cv_score}\")\n",
    "\n",
    "print(f\"Final TEST F1 score for 'rating': {rating_test_f1}\")\n",
    "print(f\"Final TEST F1 score for 'category': {category_test_f1}\")\n",
    "print(f\"Overall final TEST score: {final_test_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KarimovDO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best parameters for rating_num are: {'model': LinearRegression()}\n",
      "Best cross-validation score for rating_num is: 0.8364905740074908\n",
      "Test F1 score for rating_num is: 0.4992087191172545\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best parameters for category_num are: {'model': LinearRegression()}\n",
      "Best cross-validation score for category_num is: 0.8082170222794562\n",
      "Test F1 score for category_num is: 0.7873336567336569\n",
      "Final CV R2 score for 'rating': 0.8364905740074908\n",
      "Final CV R2 score for 'category': 0.8082170222794562\n",
      "Final TEST F1 score for 'rating': 0.4992087191172545\n",
      "Final TEST F1 score for 'category': 0.7873336567336569\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import mean_squared_error, r2_score, f1_score, make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные и мэппинги\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = stopwords.words('russian')\n",
    "\n",
    "\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=nltk_stopwords)\n",
    "\n",
    "def train_model(target_col):\n",
    "    # Извлекаем признаки и целевую переменную\n",
    "    X = data['text']\n",
    "    y = data[target_col].values\n",
    "\n",
    "    # Разделите данные на тренировочные и тестовые наборы\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "    # Примените TF-IDF векторизатор к вашим данным\n",
    "    tfidf_train = count_tf_idf.fit_transform(X_train)\n",
    "    tfidf_test = count_tf_idf.transform(X_test)\n",
    "\n",
    "    # Определите конвейер и сетку параметров для поиска по сетке\n",
    "    pipe = Pipeline([\n",
    "        ('model', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    param_grid = [\n",
    "        {\n",
    "            'model': [LinearRegression()],\n",
    "        },\n",
    "        {\n",
    "            'model': [RandomForestRegressor(random_state=42)],\n",
    "            'model__n_estimators': [100],\n",
    "            'model__max_depth': [None]\n",
    "        },\n",
    "\n",
    "    ]\n",
    "\n",
    "    # Проведите поиск по сетке, чтобы найти наилучшие параметры\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring='r2', cv=5, verbose=10, n_jobs=-1)\n",
    "    best_grid = grid.fit(tfidf_train, y_train)\n",
    "    \n",
    "    # Выведите наилучшие параметры и оценку\n",
    "    print(f\"Best parameters for {target_col} are:\", grid.best_params_)\n",
    "    print(f\"Best cross-validation score for {target_col} is:\", grid.best_score_)\n",
    "\n",
    "    # Проверка на тестовой выборке\n",
    "    test_predictions = best_grid.predict(tfidf_test)\n",
    "\n",
    "    # Восстановим буквенные рейтинги\n",
    "    inv_category_mapping = {v: k for k, v in category_mapping.items()}\n",
    "    inv_rating_mapping = {v: k for k, v in rating_mapping.items()}\n",
    "\n",
    "    if target_col == 'category_num':\n",
    "        test_predictions = np.clip(test_predictions, 0, 6)\n",
    "        test_predictions = [inv_category_mapping[round(pred)] for pred in test_predictions]\n",
    "        y_test = [inv_category_mapping[val] for val in y_test]\n",
    "    elif target_col == 'rating_num':\n",
    "        test_predictions = np.clip(test_predictions, 0, 16)\n",
    "        test_predictions = [inv_rating_mapping[round(pred)] for pred in test_predictions]\n",
    "        y_test = [inv_rating_mapping[val] for val in y_test]\n",
    "\n",
    "    # Вычислим F1-оценку\n",
    "    test_score = f1_score(y_test, test_predictions, average='weighted')\n",
    "    print(f\"Test F1 score for {target_col} is:\", test_score)\n",
    "    \n",
    "    return grid.best_score_, test_score\n",
    "\n",
    "# Получите лучшие оценки для каждой целевой переменной\n",
    "rating_cv_r2, rating_test_f1 = train_model('rating_num')\n",
    "category_cv_r2, category_test_f1 = train_model('category_num')\n",
    "\n",
    "# Выведите итоговые результаты\n",
    "print(f\"Final CV R2 score for 'rating': {rating_cv_r2}\")\n",
    "print(f\"Final CV R2 score for 'category': {category_cv_r2}\")\n",
    "\n",
    "print(f\"Final TEST F1 score for 'rating': {rating_test_f1}\")\n",
    "print(f\"Final TEST F1 score for 'category': {category_test_f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим несколько стратегий для создания новых признаков:\n",
    "\n",
    "Использование Финансовых Терминов\n",
    "Частота финансовых терминов: Создайте признаки, которые представляют собой количество упоминаний ключевых финансовых терминов, таких как \"долг\", \"прибыль\", \"риск\" и т. д., в каждом тексте.\n",
    "\n",
    "Sentiment Analysis на финансовых терминах: Проведите анализ тональности сосредоточиваясь на предложениях, в которых упоминаются финансовые термины, чтобы оценить, является ли контекст положительным, отрицательным или нейтральным.\n",
    "\n",
    "Использование Метрических Данных\n",
    "Числовые метрики: Создайте признаки, представляющие количество числовых упоминаний в тексте, или даже более сложные метрики, такие как среднее или медианное значение упоминаемых чисел.\n",
    "\n",
    "Упоминание финансовых показателей: Определите, упоминаются ли специфические финансовые показатели (например, EBITDA, P/E ratio) и создайте бинарные признаки на основе их наличия или отсутствия.\n",
    "\n",
    "Прочие Стратегии\n",
    "Кластеризация текстов: Попробуйте использовать алгоритмы кластеризации для группировки текстов по схожести тем, и используйте метки кластеров как признаки.\n",
    "\n",
    "Создание тематических дикционариев: Создайте словари с положительными и отрицательными финансовыми терминами и используйте их для создания признаков на основе числа положительных и отрицательных слов в тексте.\n",
    "\n",
    "Длина текста и структура предложения: Включите признаки, связанные с длиной текста или структурой предложения (например, средняя длина предложения)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Id                                               text category  \\\n",
      "0           0   1  повышение кредитного рейтинга  акционерного об...        A   \n",
      "1           1   2  эксперт ра подтвердил кредитный рейтинг компан...       BB   \n",
      "2           2   3  нкр повысило кредитный рейтинг ооо отэкопортсе...        A   \n",
      "3           3   4  эксперт ра присвоил кредитный рейтинг пао фоса...      AAA   \n",
      "4           4   5  марта  г ведущий рейтинговый аналитик юрова ал...      BBB   \n",
      "\n",
      "  rating                                    text_lemmatized   mlrd    mln  \\\n",
      "0      A  повышение кредитный рейтинг акционерный общест...   True  False   \n",
      "1     BB  эксперт ра подтверждать кредитный рейтинг комп...  False   True   \n",
      "2      A  нкр повышать кредитный рейтинг ооо отэкопортсе...  False   True   \n",
      "3    AAA  эксперт ра присваивать кредитный рейтинг пао ф...   True   True   \n",
      "4    BBB  марта г ведущий рейтинговый аналитик юров алла...   True  False   \n",
      "\n",
      "   rating_assessment  regulatory_requirements  ...  press_release  \\\n",
      "0               True                     True  ...          False   \n",
      "1               True                    False  ...          False   \n",
      "2               True                     True  ...          False   \n",
      "3               True                    False  ...          False   \n",
      "4               True                    False  ...          False   \n",
      "\n",
      "   open_source_information  AKR_database  reporting  additional_services  \\\n",
      "0                     True         False       True                False   \n",
      "1                     True         False       True                False   \n",
      "2                     True         False      False                False   \n",
      "3                     True         False       True                False   \n",
      "4                     True         False      False                False   \n",
      "\n",
      "   conflict_of_interest  connection_category  level  senior_unsecured_debt  \\\n",
      "0                 False                 True   True                   True   \n",
      "1                 False                False   True                   True   \n",
      "2                 False                False   True                   True   \n",
      "3                 False                False   True                   True   \n",
      "4                 False                False   True                   True   \n",
      "\n",
      "   emission  \n",
      "0     False  \n",
      "1     False  \n",
      "2     False  \n",
      "3     False  \n",
      "4     False  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Список признаков и соответствующие им ключевые слова для поиска в тексте\n",
    "features_keywords = {\n",
    "    \"mlrd\": [\"млрд\"],\n",
    "    \"mln\": [\"млн\"],\n",
    "    \"rating_assessment\": [\"rating\"],\n",
    "    \"regulatory_requirements\": [\"регуляторный\"],\n",
    "    \"disclosure\": [\"раскрытие\"],\n",
    "    \"credit_rating\": [\"кредитный\"],\n",
    "    \"joint_stock_company\": [\"общество\"],\n",
    "    \"bond_issue\": [\"облигаций\"],\n",
    "    \"RUAQ\": [\"RUAQ\"],\n",
    "    \"national_scale\": [\"шкала\"],\n",
    "    \"non_financial_company\": [\"компания\"],\n",
    "    \"agency\": [\"агентство\"],\n",
    "    \"rating_activity\": [\"деятельность\"],\n",
    "    \"financial_instrument\": [\"финансовый\"],\n",
    "    \"AKR_credit_rating\": [\"AKR\"],\n",
    "    \"credit_rating_forecast\": [\"прогноз\"],\n",
    "    \"press_release\": [\"пресс-релиз\"],\n",
    "    \"open_source_information\": [\"информация\"],\n",
    "    \"AKR_database\": [\"база данных\"],\n",
    "    \"reporting\": [\"отчетность\"],\n",
    "    \"additional_services\": [\"услуги\"],\n",
    "    \"conflict_of_interest\": [\"интересов\"],\n",
    "    \"connection_category\": [\"категория\"],\n",
    "    \"level\": [\"уровень\"],\n",
    "    \"senior_unsecured_debt\": [\"долг\"],\n",
    "    \"emission\": [\"эмиссии\"],\n",
    "    }\n",
    "\n",
    "for feature, keywords in features_keywords.items():\n",
    "    data[feature] = data[\"text_lemmatized\"].apply(lambda x: any(keyword in x for keyword in keywords))\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
