{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализатор текстовых пресс-релизов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: На основании исторических пресс-релизов кредитных рейтинговых агентств участникам хакатона необходимо построить интерпретируемую ML-модель, устанавливающую взаимосвязь между текстом пресс-релиза и присвоенным кредитным рейтингом по национальной рейтинговой шкале Российской Федерации для организации с учетом методологических особенностей оценки рейтинга. ML-модель должна не просто устанавливать соответствие текста пресс-релиза кредитному рейтингу, но также и выделять ключевые конструкции в тексте, соответствующие присвоенному кредитному рейтингу.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План\n",
    "\n",
    "Исходя из поставленной зажачи мы сформировали план\n",
    "1. Загрузить данные\n",
    "2. Оценить данные, если нужно, почистить, лематизировать\n",
    "3. Использовать для токенизации инструмент TfidfVectorizer\n",
    "4. Построить на основе полученных векторов разные модели предсказания кредитного рейтинга\n",
    "5. Использовать трансформер BERT\n",
    "6. Построить на основе полученных векторов разные модели предсказания кредитного рейтинга\n",
    "7. Оценить результаты и сделать выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from tqdm import notebook\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import torch\n",
    "import transformers as ppb\n",
    "import lightgbm as lgb\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import wordnet\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('CRA_train_1200.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Повышение кредитного рейтинга  Акционерного об...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>«Эксперт РА» подтвердил кредитный рейтинг комп...</td>\n",
       "      <td>BB</td>\n",
       "      <td>BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>НКР повысило кредитный рейтинг ООО \"ОТЭКО-Порт...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>«Эксперт РА» присвоил кредитный рейтинг ПАО «Ф...</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>29 марта 2023 г. Ведущий рейтинговый аналитик ...</td>\n",
       "      <td>BBB</td>\n",
       "      <td>BBB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text category rating\n",
       "0   1  Повышение кредитного рейтинга  Акционерного об...        A      A\n",
       "1   2  «Эксперт РА» подтвердил кредитный рейтинг комп...       BB     BB\n",
       "2   3  НКР повысило кредитный рейтинг ООО \"ОТЭКО-Порт...        A      A\n",
       "3   4  «Эксперт РА» присвоил кредитный рейтинг ПАО «Ф...      AAA    AAA\n",
       "4   5  29 марта 2023 г. Ведущий рейтинговый аналитик ...      BBB    BBB"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\n",
    "    'pr_txt': 'text',\n",
    "    'Категория': 'category',\n",
    "    'Уровень рейтинга': 'rating'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'BB', 'AAA', 'BBB', 'AA+', 'BB+', 'BB-', 'A-', 'A+', 'B',\n",
       "       'AA-', 'BBB+', 'BBB-', 'B-', 'AA', 'B+', 'C'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    'C': 0, \n",
    "    'B': 1, \n",
    "    'BB': 2, \n",
    "    'BBB': 3, \n",
    "    'A': 4, \n",
    "    'AA': 5, \n",
    "    'AAA': 6\n",
    "}\n",
    "\n",
    "data['category_num'] = data['category'].replace(category_mapping)\n",
    "\n",
    "rating_mapping = {\n",
    "    'C': 0, \n",
    "    'B-': 1, \n",
    "    'B': 2, \n",
    "    'B+': 3, \n",
    "    'BB-': 4, \n",
    "    'BB': 5, \n",
    "    'BB+': 6, \n",
    "    'BBB-': 7, \n",
    "    'BBB': 8, \n",
    "    'BBB+': 9, \n",
    "    'A-': 10, \n",
    "    'A': 11, \n",
    "    'A+': 12, \n",
    "    'AA-': 13, \n",
    "    'AA': 14, \n",
    "    'AA+': 15, \n",
    "    'AAA': 16\n",
    "}\n",
    "\n",
    "data['rating_num'] = data['rating'].replace(rating_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Zа-яА-Я ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Денис\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 1200/1200 [18:04<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id                                               text category rating  \\\n",
      "0   1  повышение кредитного рейтинга  акционерного об...        A      A   \n",
      "1   2  эксперт ра подтвердил кредитный рейтинг компан...       BB     BB   \n",
      "2   3  нкр повысило кредитный рейтинг ооо отэкопортсе...        A      A   \n",
      "3   4  эксперт ра присвоил кредитный рейтинг пао фоса...      AAA    AAA   \n",
      "4   5  марта  г ведущий рейтинговый аналитик юрова ал...      BBB    BBB   \n",
      "\n",
      "                                     text_lemmatized  \n",
      "0  повышение кредитный рейтинг акционерный общест...  \n",
      "1  эксперт ра подтверждать кредитный рейтинг комп...  \n",
      "2  нкр повышать кредитный рейтинг ооо отэкопортсе...  \n",
      "3  эксперт ра присваивать кредитный рейтинг пао ф...  \n",
      "4  марта г ведущий рейтинговый аналитик юров алла...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "# Загрузка русских стоп-слов\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "\n",
    "\n",
    "def lemmatize_text(corpus):\n",
    "    corpus_new = []\n",
    "    for sentence in tqdm(corpus):\n",
    "        lemmatized_sentence = m.lemmatize(sentence)\n",
    "        cleaned_sentence = ' '.join([word for word in lemmatized_sentence if word.strip() and word not in russian_stopwords])\n",
    "        corpus_new.append(cleaned_sentence)\n",
    "    return corpus_new\n",
    "\n",
    "\n",
    "\n",
    "data['text_lemmatized'] = lemmatize_text(data['text'])\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 31 candidates, totalling 155 fits\n",
      "Best parameters for rating are: {'model': SVC(C=10, kernel='linear', random_state=42), 'model__C': 10, 'model__kernel': 'linear'}\n",
      "Best cross-validation score for rating is: 0.6108157606282278\n",
      "Test F1 score for rating is: 0.6761702475812629\n",
      "Fitting 5 folds for each of 31 candidates, totalling 155 fits\n",
      "Best parameters for category are: {'model': LogisticRegression(C=13, penalty='l1', random_state=42, solver='liblinear'), 'model__C': 13, 'model__penalty': 'l1'}\n",
      "Best cross-validation score for category is: 0.785018814950238\n",
      "Test F1 score for category is: 0.7969036640890367\n",
      "Final CV F1 score for 'rating': 0.6108157606282278\n",
      "Final CV F1 score for 'category': 0.785018814950238\n",
      "Overall final CV score: 0.6717868296409314\n",
      "Final TEST F1 score for 'rating': 0.6761702475812629\n",
      "Final TEST F1 score for 'category': 0.7969036640890367\n",
      "Overall final TEST score: 0.7184269433589837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "nltk_stopwords = list(nltk_stopwords.words('russian'))\n",
    "extra_stopwords = [\n",
    "    'далее', 'также', 'что', 'в', 'с', 'и', 'на', 'по', 'а', 'за', '—', 'как', \n",
    "    'у', 'до', 'средней', 'очень', 'один', 'это', 'средняя', '«', '»', '(', ')', \n",
    "    '№', '—', 'году', 'одной', 'посредством', 'ранее', 'большого', 'которая', \n",
    "    'который', 'этом', 'является', 'один', 'другой', 'доли', 'доля', 'их', \n",
    "    'которого', 'его', 'средний', 'средние', 'уровень', 'производителей', \n",
    "    'высокие', 'низкой', 'средней', 'продукции', 'компании', 'компания', \n",
    "    'продукция', 'оценка', 'оценки', 'оценку', 'показатели', 'показатель', \n",
    "    'факторы', 'фактор', 'уровня', 'профиля', 'бизнес', 'бизнеса', 'уровень', \n",
    "    'уровня', 'рейтинг', 'рейтинга', 'рейтингу', 'производства', 'производство'\n",
    "]\n",
    "nltk_stopwords.extend(extra_stopwords)\n",
    "count_tf_idf = TfidfVectorizer(stop_words=nltk_stopwords)\n",
    "\n",
    "def train_model(target_col):\n",
    "    # Извлекаем признаки и целевую переменную\n",
    "    X = data['text']\n",
    "    y = data[target_col].values\n",
    "\n",
    "    # Разделите данные на тренировочные и тестовые наборы\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "    # Примените TF-IDF векторизатор к вашим данным\n",
    "    tfidf_train = count_tf_idf.fit_transform(X_train)\n",
    "    tfidf_test = count_tf_idf.transform(X_test)\n",
    "\n",
    "    # Определите конвейер и сетку параметров для поиска по сетке\n",
    "    pipe = Pipeline([\n",
    "        ('model', LogisticRegression(random_state=1, solver='liblinear', max_iter=200))\n",
    "    ])\n",
    "\n",
    "    param_grid = [\n",
    "    {\n",
    "        'model': [LogisticRegression(random_state=42, solver='liblinear')],\n",
    "        'model__C': list(range(1, 15, 3)),\n",
    "        'model__penalty': ['l1', 'l2']\n",
    "    },\n",
    "    {\n",
    "        'model': [RandomForestClassifier(random_state=42)],\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    {\n",
    "        'model': [SVC(random_state=42)],\n",
    "        'model__C': [0.1, 1, 10],\n",
    "        'model__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    {\n",
    "        'model': [MultinomialNB()],\n",
    "        'model__alpha': [0.1, 1.0, 10.0]\n",
    "    }\n",
    "    ]\n",
    "\n",
    "        # Проведите поиск по сетке, чтобы найти наилучшие параметры\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring=make_scorer(f1_score, average='weighted'), cv=5, verbose=True, n_jobs=-1)\n",
    "    best_grid = grid.fit(tfidf_train, y_train)\n",
    "    \n",
    "    # Выведите наилучшие параметры и оценку\n",
    "    print(f\"Best parameters for {target_col} are:\", grid.best_params_)\n",
    "    print(f\"Best cross-validation score for {target_col} is:\", grid.best_score_)\n",
    "\n",
    "    # Проверка на тестовой выборке\n",
    "    tfidf_test = count_tf_idf.transform(X_test)\n",
    "    test_predictions = best_grid.predict(tfidf_test)\n",
    "    test_score = f1_score(y_test, test_predictions, average='weighted')\n",
    "    print(f\"Test F1 score for {target_col} is:\", test_score)\n",
    "    \n",
    "    return grid.best_score_, test_score\n",
    "\n",
    "# Получите лучшие оценки для каждой целевой переменной\n",
    "rating_cv_f1, rating_test_f1 = train_model('rating')\n",
    "category_cv_f1, category_test_f1 = train_model('category')\n",
    "\n",
    "# Рассчитайте взвешенный итоговый результат\n",
    "final_cv_score = (rating_cv_f1 * 0.65) + (category_cv_f1 * 0.35)\n",
    "final_test_score = (rating_test_f1 * 0.65) + (category_test_f1 * 0.35)\n",
    "\n",
    "print(f\"Final CV F1 score for 'rating': {rating_cv_f1}\")\n",
    "print(f\"Final CV F1 score for 'category': {category_cv_f1}\")\n",
    "print(f\"Overall final CV score: {final_cv_score}\")\n",
    "\n",
    "print(f\"Final TEST F1 score for 'rating': {rating_test_f1}\")\n",
    "print(f\"Final TEST F1 score for 'category': {category_test_f1}\")\n",
    "print(f\"Overall final TEST score: {final_test_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KarimovDO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, f1_score, make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные и мэппинги\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = stopwords.words('russian')\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=nltk_stopwords)\n",
    "\n",
    "def train_model(target_col):\n",
    "    # Извлекаем признаки и целевую переменную\n",
    "    X = data['text']\n",
    "    y = data[target_col].values\n",
    "\n",
    "    # Разделите данные на тренировочные и тестовые наборы\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "    # Примените TF-IDF векторизатор к вашим данным\n",
    "    tfidf_train = count_tf_idf.fit_transform(X_train)\n",
    "    tfidf_test = count_tf_idf.transform(X_test)\n",
    "\n",
    "    # Определите конвейер и сетку параметров для поиска по сетке\n",
    "    pipe = Pipeline([\n",
    "        ('model', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    param_grid = [\n",
    "    {\n",
    "        'model': [LinearRegression()],\n",
    "    },\n",
    "    {\n",
    "        'model': [RandomForestRegressor(random_state=42)],\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    {\n",
    "        'model': [SVR()],\n",
    "        'model__C': [0.1, 1, 10],\n",
    "        'model__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    ]\n",
    "\n",
    "    # Проведите поиск по сетке, чтобы найти наилучшие параметры\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring='r2', cv=5, verbose=True, n_jobs=-1)\n",
    "    best_grid = grid.fit(tfidf_train, y_train)\n",
    "    \n",
    "    # Выведите наилучшие параметры и оценку\n",
    "    print(f\"Best parameters for {target_col} are:\", grid.best_params_)\n",
    "    print(f\"Best cross-validation score for {target_col} is:\", grid.best_score_)\n",
    "\n",
    "    # Проверка на тестовой выборке\n",
    "    test_predictions = best_grid.predict(tfidf_test)\n",
    "\n",
    "    # Восстановим буквенные рейтинги\n",
    "    inv_category_mapping = {v: k for k, v in category_mapping.items()}\n",
    "    inv_rating_mapping = {v: k for k, v in rating_mapping.items()}\n",
    "\n",
    "    if target_col == 'category_num':\n",
    "        test_predictions = [inv_category_mapping[round(pred)] for pred in test_predictions]\n",
    "        y_test = [inv_category_mapping[val] for val in y_test]\n",
    "    elif target_col == 'rating_num':\n",
    "        test_predictions = [inv_rating_mapping[round(pred)] for pred in test_predictions]\n",
    "        y_test = [inv_rating_mapping[val] for val in y_test]\n",
    "\n",
    "    # Вычислим F1-оценку\n",
    "    test_score = f1_score(y_test, test_predictions, average='weighted')\n",
    "    print(f\"Test F1 score for {target_col} is:\", test_score)\n",
    "    \n",
    "    return grid.best_score_, test_score\n",
    "\n",
    "# Получите лучшие оценки для каждой целевой переменной\n",
    "rating_cv_r2, rating_test_f1 = train_model('rating_num')\n",
    "category_cv_r2, category_test_f1 = train_model('category_num')\n",
    "\n",
    "# Выведите итоговые результаты\n",
    "print(f\"Final CV R2 score for 'rating': {rating_cv_r2}\")\n",
    "print(f\"Final CV R2 score for 'category': {category_cv_r2}\")\n",
    "\n",
    "print(f\"Final TEST F1 score for 'rating': {rating_test_f1}\")\n",
    "print(f\"Final TEST F1 score for 'category': {category_test_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим несколько стратегий для создания новых признаков:\n",
    "\n",
    "Использование Финансовых Терминов\n",
    "Частота финансовых терминов: Создайте признаки, которые представляют собой количество упоминаний ключевых финансовых терминов, таких как \"долг\", \"прибыль\", \"риск\" и т. д., в каждом тексте.\n",
    "\n",
    "Sentiment Analysis на финансовых терминах: Проведите анализ тональности сосредоточиваясь на предложениях, в которых упоминаются финансовые термины, чтобы оценить, является ли контекст положительным, отрицательным или нейтральным.\n",
    "\n",
    "Использование Метрических Данных\n",
    "Числовые метрики: Создайте признаки, представляющие количество числовых упоминаний в тексте, или даже более сложные метрики, такие как среднее или медианное значение упоминаемых чисел.\n",
    "\n",
    "Упоминание финансовых показателей: Определите, упоминаются ли специфические финансовые показатели (например, EBITDA, P/E ratio) и создайте бинарные признаки на основе их наличия или отсутствия.\n",
    "\n",
    "Прочие Стратегии\n",
    "Кластеризация текстов: Попробуйте использовать алгоритмы кластеризации для группировки текстов по схожести тем, и используйте метки кластеров как признаки.\n",
    "\n",
    "Создание тематических дикционариев: Создайте словари с положительными и отрицательными финансовыми терминами и используйте их для создания признаков на основе числа положительных и отрицательных слов в тексте.\n",
    "\n",
    "Длина текста и структура предложения: Включите признаки, связанные с длиной текста или структурой предложения (например, средняя длина предложения)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KarimovDO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KarimovDO\\Documents\\GitHub\\medis_cor\\hak1\\h.ipynb Ячейка 19\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KarimovDO/Documents/GitHub/medis_cor/hak1/h.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mpunkt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KarimovDO/Documents/GitHub/medis_cor/hak1/h.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Получаем уникальные значения рейтинга\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KarimovDO/Documents/GitHub/medis_cor/hak1/h.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m unique_ratings \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KarimovDO/Documents/GitHub/medis_cor/hak1/h.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m rating \u001b[39min\u001b[39;00m unique_ratings:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KarimovDO/Documents/GitHub/medis_cor/hak1/h.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     text_tokens \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "4\n",
    "\n",
    "# Убедитесь, что nltk корпусы загружены\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Получаем уникальные значения рейтинга\n",
    "unique_ratings = data['rating'].unique()\n",
    "\n",
    "for rating in unique_ratings:\n",
    "    text_tokens = []\n",
    "\n",
    "    # Получаем тексты для текущего рейтинга и проводим токенизацию\n",
    "    for i in tqdm(data[data['rating'] == rating].text_lemmatized):\n",
    "        token_vr = word_tokenize(i)\n",
    "        for j in token_vr:\n",
    "            text_tokens.append(j)\n",
    "    \n",
    "    # Создаем объект nltk.Text\n",
    "    text = nltk.Text(text_tokens)\n",
    "    \n",
    "    # Создаем объект FreqDist и строим график\n",
    "    fdist = FreqDist(text)\n",
    "    fdist.plot(30, cumulative=False)\n",
    "    \n",
    "    # Создаем облако слов\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        max_font_size=200,\n",
    "        width=1000, height=800,\n",
    "        random_state=42,\n",
    "    ).generate(\" \".join(text))\n",
    "\n",
    "    # Строим график облака слов\n",
    "    fig = plt.figure(figsize=(12, 14))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.title(f\"Rating: {rating}\", fontsize=45)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Id                                               text category  \\\n",
      "0           0   1  повышение кредитного рейтинга  акционерного об...        A   \n",
      "1           1   2  эксперт ра подтвердил кредитный рейтинг компан...       BB   \n",
      "2           2   3  нкр повысило кредитный рейтинг ооо отэкопортсе...        A   \n",
      "3           3   4  эксперт ра присвоил кредитный рейтинг пао фоса...      AAA   \n",
      "4           4   5  марта  г ведущий рейтинговый аналитик юрова ал...      BBB   \n",
      "\n",
      "  rating                                    text_lemmatized   mlrd    mln  \\\n",
      "0      A  повышение кредитный рейтинг акционерный общест...   True  False   \n",
      "1     BB  эксперт ра подтверждать кредитный рейтинг комп...  False   True   \n",
      "2      A  нкр повышать кредитный рейтинг ооо отэкопортсе...  False   True   \n",
      "3    AAA  эксперт ра присваивать кредитный рейтинг пао ф...   True   True   \n",
      "4    BBB  марта г ведущий рейтинговый аналитик юров алла...   True  False   \n",
      "\n",
      "   rating_assessment  regulatory_requirements  ...  press_release  \\\n",
      "0               True                     True  ...          False   \n",
      "1               True                    False  ...          False   \n",
      "2               True                     True  ...          False   \n",
      "3               True                    False  ...          False   \n",
      "4               True                    False  ...          False   \n",
      "\n",
      "   open_source_information  AKR_database  reporting  additional_services  \\\n",
      "0                     True         False       True                False   \n",
      "1                     True         False       True                False   \n",
      "2                     True         False      False                False   \n",
      "3                     True         False       True                False   \n",
      "4                     True         False      False                False   \n",
      "\n",
      "   conflict_of_interest  connection_category  level  senior_unsecured_debt  \\\n",
      "0                 False                 True   True                   True   \n",
      "1                 False                False   True                   True   \n",
      "2                 False                False   True                   True   \n",
      "3                 False                False   True                   True   \n",
      "4                 False                False   True                   True   \n",
      "\n",
      "   emission  \n",
      "0     False  \n",
      "1     False  \n",
      "2     False  \n",
      "3     False  \n",
      "4     False  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Список признаков и соответствующие им ключевые слова для поиска в тексте\n",
    "features_keywords = {\n",
    "    \"mlrd\": [\"млрд\"],\n",
    "    \"mln\": [\"млн\"],\n",
    "    \"rating_assessment\": [\"rating\"],\n",
    "    \"regulatory_requirements\": [\"регуляторный\"],\n",
    "    \"disclosure\": [\"раскрытие\"],\n",
    "    \"credit_rating\": [\"кредитный\"],\n",
    "    \"joint_stock_company\": [\"общество\"],\n",
    "    \"bond_issue\": [\"облигаций\"],\n",
    "    \"RUAQ\": [\"RUAQ\"],\n",
    "    \"national_scale\": [\"шкала\"],\n",
    "    \"non_financial_company\": [\"компания\"],\n",
    "    \"agency\": [\"агентство\"],\n",
    "    \"rating_activity\": [\"деятельность\"],\n",
    "    \"financial_instrument\": [\"финансовый\"],\n",
    "    \"AKR_credit_rating\": [\"AKR\"],\n",
    "    \"credit_rating_forecast\": [\"прогноз\"],\n",
    "    \"press_release\": [\"пресс-релиз\"],\n",
    "    \"open_source_information\": [\"информация\"],\n",
    "    \"AKR_database\": [\"база данных\"],\n",
    "    \"reporting\": [\"отчетность\"],\n",
    "    \"additional_services\": [\"услуги\"],\n",
    "    \"conflict_of_interest\": [\"интересов\"],\n",
    "    \"connection_category\": [\"категория\"],\n",
    "    \"level\": [\"уровень\"],\n",
    "    \"senior_unsecured_debt\": [\"долг\"],\n",
    "    \"emission\": [\"эмиссии\"],\n",
    "    }\n",
    "\n",
    "for feature, keywords in features_keywords.items():\n",
    "    data[feature] = data[\"text_lemmatized\"].apply(lambda x: any(keyword in x for keyword in keywords))\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Id', 'text', 'category', 'rating', 'text_lemmatized',\n",
       "       'mlrd', 'mln', 'rating_assessment', 'regulatory_requirements',\n",
       "       'disclosure', 'credit_rating', 'joint_stock_company', 'bond_issue',\n",
       "       'RUAQ', 'national_scale', 'non_financial_company', 'agency',\n",
       "       'rating_activity', 'financial_instrument', 'AKR_credit_rating',\n",
       "       'credit_rating_forecast', 'press_release', 'open_source_information',\n",
       "       'AKR_database', 'reporting', 'additional_services',\n",
       "       'conflict_of_interest', 'connection_category', 'level',\n",
       "       'senior_unsecured_debt', 'emission'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Денис\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 192 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n192 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 724, in fit_transform\n    self._validate_column_callables(X)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 426, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 450, in _get_column_indices\n    raise ValueError(\nValueError: Selected columns, ['text_lemmatized'], are not unique in dataframe\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 53\u001b[0m\n\u001b[0;32m     37\u001b[0m param_grid \u001b[39m=\u001b[39m [\n\u001b[0;32m     38\u001b[0m     {\n\u001b[0;32m     39\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: [LGBMClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     }\n\u001b[0;32m     47\u001b[0m ]\n\u001b[0;32m     50\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(pipe, param_grid\u001b[39m=\u001b[39mparam_grid, scoring\u001b[39m=\u001b[39mmake_scorer(f1_score, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m), cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m best_grid \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     56\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest parameters are:\u001b[39m\u001b[39m'\u001b[39m, grid\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     57\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest score is:\u001b[39m\u001b[39m'\u001b[39m, grid\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[0;32m    853\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 192 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n192 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 724, in fit_transform\n    self._validate_column_callables(X)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 426, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n  File \"c:\\Users\\Денис\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 450, in _get_column_indices\n    raise ValueError(\nValueError: Selected columns, ['text_lemmatized'], are not unique in dataframe\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = list(nltk_stopwords.words('russian'))\n",
    "\n",
    "\n",
    "y = data['rating'].values\n",
    "X = data[['text_lemmatized', 'rating', 'text_lemmatized',\n",
    "       'mlrd', 'mln', 'rating_assessment', 'regulatory_requirements',\n",
    "       'disclosure', 'credit_rating', 'joint_stock_company', 'bond_issue',\n",
    "       'RUAQ', 'national_scale', 'non_financial_company', 'agency',\n",
    "       'rating_activity', 'financial_instrument', 'AKR_credit_rating',\n",
    "       'credit_rating_forecast', 'press_release', 'open_source_information',\n",
    "       'AKR_database', 'reporting', 'additional_services',\n",
    "       'conflict_of_interest', 'connection_category', 'level',\n",
    "       'senior_unsecured_debt', 'emission']]  \n",
    "\n",
    "X_train, X_vr, y_train, y_vr = train_test_split(X, y, test_size = 0.4, random_state = 42, stratify = y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_vr, y_vr, test_size=0.5, random_state = 42, stratify = y_vr)\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', tfidf_vectorizer, 'text_lemmatized'),\n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(random_state=1, solver='liblinear', max_iter=200))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [LGBMClassifier(random_state=42)],\n",
    "        'model__num_leaves': [31, 60],\n",
    "        'model__max_depth': [-1, 30],\n",
    "        'model__learning_rate': [0.1, 0.01],\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'preprocessor__tfidf__max_features': [5000, None],  \n",
    "        'preprocessor__tfidf__ngram_range': [(1, 1), (1, 2)],  \n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, scoring=make_scorer(f1_score, average='weighted'), cv=3, verbose=True, n_jobs=-1)\n",
    "\n",
    "\n",
    "best_grid = grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters are:', grid.best_params_)\n",
    "print('Best score is:', grid.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
